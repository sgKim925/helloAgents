from typing import List, Dict, Any, Optional
from prompts import INITIAL_PROMPT_TEMPLATE, REFLECT_PROMPT_TEMPLATE, REFINE_PROMPT_TEMPLATE
from helloClient import HelloAgentsLLM
from dotenv import load_dotenv


load_dotenv()


class Memory:
    """
    ä¸€ä¸ªç®€å•çš„çŸ­æœŸè®°å¿†æ¨¡å—ï¼Œç”¨äºå­˜å‚¨æ™ºèƒ½ä½“çš„è¡ŒåŠ¨ä¸åæ€è½¨è¿¹ã€‚
    """

    def __init__(self):
        """
        åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨æ¥å­˜å‚¨æ‰€æœ‰è®°å½•ã€‚
        """
        self.records: List[Dict[str, Any]] = []

    def add_record(self, record_type: str, content: str):
        """
        å‘è®°å¿†ä¸­æ·»åŠ ä¸€æ¡æ–°è®°å½•ã€‚

        å‚æ•°:
        - record_type (str): è®°å½•çš„ç±»å‹ ('execution' æˆ– 'reflection')ã€‚
        - content (str): è®°å½•çš„å…·ä½“å†…å®¹ (ä¾‹å¦‚ï¼Œç”Ÿæˆçš„ä»£ç æˆ–åæ€çš„åé¦ˆ)ã€‚
        """
        record = {"type": record_type, "content": content}
        self.records.append(record)
        print(f"ğŸ“ è®°å¿†å·²æ›´æ–°ï¼Œæ–°å¢ä¸€æ¡ '{record_type}' è®°å½•ã€‚")

    def get_trajectory(self) -> str:
        """
        å°†æ‰€æœ‰è®°å¿†è®°å½•æ ¼å¼åŒ–ä¸ºä¸€ä¸ªè¿è´¯çš„å­—ç¬¦ä¸²æ–‡æœ¬ï¼Œç”¨äºæ„å»ºæç¤ºè¯ã€‚
        """
        trajectory_parts = []
        for record in self.records:
            if record['type'] == 'execution':
                trajectory_parts.append(f"--- ä¸Šä¸€è½®å°è¯• (ä»£ç ) ---\n{record['content']}")
            elif record['type'] == 'reflection':
                trajectory_parts.append(f"--- è¯„å®¡å‘˜åé¦ˆ ---\n{record['content']}")
        
        return "\n\n".join(trajectory_parts)

    def get_last_execution(self) -> Optional[str]:
        """
        è·å–æœ€è¿‘ä¸€æ¬¡çš„æ‰§è¡Œç»“æœ (ä¾‹å¦‚ï¼Œæœ€æ–°ç”Ÿæˆçš„ä»£ç )ã€‚
        å¦‚æœä¸å­˜åœ¨ï¼Œåˆ™è¿”å› Noneã€‚
        """
        for record in reversed(self.records):
            if record['type'] == 'execution':
                return record['content']
        return None


class ReflectionAgent:
    def __init__(self, llm_client, max_iterations=3):
        self.llm_client = llm_client
        self.memory = Memory()
        self.max_iterations = max_iterations

    def run(self, task: str):
        print(f"\n--- å¼€å§‹å¤„ç†ä»»åŠ¡ ---\nä»»åŠ¡: {task}")

        # --- 1. åˆå§‹æ‰§è¡Œ ---
        print("\n--- æ­£åœ¨è¿›è¡Œåˆå§‹å°è¯• ---")
        initial_prompt = INITIAL_PROMPT_TEMPLATE.format(task=task)
        initial_code = self._get_llm_response(initial_prompt)
        self.memory.add_record("execution", initial_code)

        # --- 2. è¿­ä»£å¾ªç¯ï¼šåæ€ä¸ä¼˜åŒ– ---
        for i in range(self.max_iterations):
            print(f"\n--- ç¬¬ {i+1}/{self.max_iterations} è½®è¿­ä»£ ---")

            # a. åæ€
            print("\n-> æ­£åœ¨è¿›è¡Œåæ€...")
            last_code = self.memory.get_last_execution()
            reflect_prompt = REFLECT_PROMPT_TEMPLATE.format(task=task, code=last_code)
            feedback = self._get_llm_response(reflect_prompt)
            self.memory.add_record("reflection", feedback)

            # b. æ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
            if "æ— éœ€æ”¹è¿›" in feedback or "no need for improvement" in feedback.lower():
                print("\nâœ… åæ€è®¤ä¸ºä»£ç å·²æ— éœ€æ”¹è¿›ï¼Œä»»åŠ¡å®Œæˆã€‚")
                break

            # c. ä¼˜åŒ–
            print("\n-> æ­£åœ¨è¿›è¡Œä¼˜åŒ–...")
            refine_prompt = REFINE_PROMPT_TEMPLATE.format(
                task=task,
                last_code_attempt=last_code,
                feedback=feedback
            )
            refined_code = self._get_llm_response(refine_prompt)
            self.memory.add_record("execution", refined_code)
        
        final_code = self.memory.get_last_execution()
        print(f"\n--- ä»»åŠ¡å®Œæˆ ---\næœ€ç»ˆç”Ÿæˆçš„ä»£ç :\n{final_code}")
        return final_code

    def _get_llm_response(self, prompt: str) -> str:
        """ä¸€ä¸ªè¾…åŠ©æ–¹æ³•ï¼Œç”¨äºè°ƒç”¨LLMå¹¶è·å–å®Œæ•´çš„æµå¼å“åº”ã€‚"""
        messages = [{"role": "user", "content": prompt}]
        # ç¡®ä¿èƒ½å¤„ç†ç”Ÿæˆå™¨å¯èƒ½è¿”å›Noneçš„æƒ…å†µ
        response_text = self.llm_client.think(messages=messages) or ""
        return response_text

if __name__ == '__main__':
    # 1. åˆå§‹åŒ–LLMå®¢æˆ·ç«¯ (è¯·ç¡®ä¿ä½ çš„ .env å’Œ llm_client.py æ–‡ä»¶é…ç½®æ­£ç¡®)
    try:
        llm_client = HelloAgentsLLM()
    except Exception as e:
        print(f"åˆå§‹åŒ–LLMå®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")
        exit()

    # 2. åˆå§‹åŒ– Reflection æ™ºèƒ½ä½“ï¼Œè®¾ç½®æœ€å¤šè¿­ä»£2è½®
    agent = ReflectionAgent(llm_client, max_iterations=10)

    # 3. å®šä¹‰ä»»åŠ¡å¹¶è¿è¡Œæ™ºèƒ½ä½“
    task = "ç¼–å†™ä¸€ä¸ªPythonå‡½æ•°ï¼Œæ‰¾å‡º1åˆ°nä¹‹é—´æ‰€æœ‰çš„ç´ æ•° (prime numbers)ã€‚"
    agent.run(task)